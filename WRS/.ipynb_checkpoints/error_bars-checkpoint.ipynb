{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b34c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys, copy, os, shutil\n",
    "from tqdm.notebook import tqdm\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "# translations for our datasets\n",
    "dataset_descs = {\"avazu-app_binary_sparse\" : \"Avazu (App)\",\n",
    "                 \"avazu-site_binary_sparse\" : \"Avazu (Site)\",\n",
    "                 \"criteo_binary_sparse\" : \"Criteo\",\n",
    "                 \"dexter_binary_sparse\" : \"Dexter\",\n",
    "                 \"dorothea_binary_sparse\" : \"Dorothea\",\n",
    "                 \"kdd2010-a_binary_sparse\" : \"KDD2010 (Algebra)\",\n",
    "                 \"mnist8-4+9_binary_sparse\" : \"MNIST8 (4+9)\",\n",
    "                 \"news20_binary_sparse\" : \"News20\",\n",
    "                 \"newsgroups_binary_sparse\" : \"Newsgroups (Binary, CS)\",\n",
    "                 \"pcmac_binary_sparse\" : \"PCMAC\",\n",
    "                 \"rcv1_binary_sparse\" : \"RCV1\",\n",
    "                 \"real-sim_binary_sparse\" : \"Real-Sim\",\n",
    "                 \"sst2_binary_sparse\" : \"SST-2\",\n",
    "                 \"url_binary_sparse\" : \"URL\",\n",
    "                 \"w8a_binary_sparse\" : \"W8A\",\n",
    "                 \"webspam_binary_sparse\" : \"Webspam\"}\n",
    "\n",
    "# load in our logs\n",
    "master = pd.read_csv(\"logs/master.csv\")\n",
    "\n",
    "# create a subdirectory\n",
    "if \"errorbars\" not in os.listdir(\"figures\"):\n",
    "    os.mkdir(\"figures/errorbars\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed6c1a7",
   "metadata": {},
   "source": [
    "# Error Bars for L1 (\"Relative Oracle Performance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4851fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# go thru each combination of base model + weight_scheme\n",
    "for model in [\"PAC\", \"FSOL\"]:\n",
    "    for weight_scheme in [\"dense\", \"exp-dense\"]:\n",
    "        \n",
    "        # start our figure\n",
    "        fig, ax = plt.subplots(4, 4, dpi=200, figsize=(14, 12))\n",
    "        \n",
    "        success = 0\n",
    "        \n",
    "        # go thru each of our datasets\n",
    "        for i, dataset in enumerate(dataset_descs.keys()):\n",
    "            \n",
    "            # beautify our subplot immediately\n",
    "            ax[i // 4, i % 4].grid()\n",
    "            ax[i // 4, i % 4].set_title(dataset_descs[dataset], fontsize=15)\n",
    "            \n",
    "            # set to store our base values\n",
    "            base_vals = []\n",
    "            \n",
    "            # load in the instantaneous test accuracies for seed=0\n",
    "            if model == \"PAC\":\n",
    "\n",
    "                # immediately load in the best hyperparameters for this dataset + model\n",
    "                log10Cerr = pd.read_csv(\"base_variants/PAC_hparams.csv\")\\\n",
    "                .query(f\"dataset == '{dataset}'\")[[\"log10Cerr\"]].values[0,0]\n",
    "                log10Cerr = int(log10Cerr)\n",
    "\n",
    "                # load in the file + get the values that we should be plotting\n",
    "                for seed in range(5):\n",
    "                    logs_inst = pd.read_csv(f\"../hparam_tuning/results/{model}/{dataset}/model={model}_log10Cerr={log10Cerr}_seed={seed}_metrics.csv\")\n",
    "                    base_vals.append((logs_inst[\"inst_test-set-acc\"][1:].cummax().values - logs_inst[\"inst_test-set-acc\"][1:].values).mean())\n",
    "                    \n",
    "            elif model == \"FSOL\":\n",
    "\n",
    "                # immediately load in the best hyperparameters for this dataset + model\n",
    "                log2eta, log10lmbda = pd.read_csv(\"base_variants/FSOL_hparams.csv\")\\\n",
    "                .query(f\"dataset == '{dataset}'\")[[\"log2eta\", \"log10lmbda\"]].values[0]\n",
    "                log2eta, log10lmbda = log2eta, log10lmbda\n",
    "\n",
    "                # load in the file + get the values that we should be plotting\n",
    "                for seed in range(5):\n",
    "                    logs_inst = pd.read_csv(f\"../hparam_tuning/results/{model}/{dataset}/model={model}_log2eta={log2eta}_log10lmbda={log10lmbda}_seed={seed}_metrics.csv\")\n",
    "                    base_vals.append((logs_inst[\"inst_test-set-acc\"][1:].cummax().values - logs_inst[\"inst_test-set-acc\"][1:].values).mean())\n",
    "        \n",
    "            # put a confidence band in light green + line at the mean (MIN + MAX)\n",
    "            ax[i // 4, i % 4].axhline(y=np.mean(base_vals), color=\"green\")\n",
    "            ax[i // 4, i % 4].fill_between([0-1/2, 2, 3, 6+1/2], [np.min(base_vals)] * 4, [np.max(base_vals)] * 4, \n",
    "                                           alpha=0.5, color=\"green\")\n",
    "            \n",
    "            # let's showing up our variants\n",
    "            for j, K in enumerate([1, 4, 16, 64]):\n",
    "                \n",
    "                # create a counter to help us out\n",
    "                counter = 0\n",
    "                \n",
    "                # plot all four error bars for this value of K\n",
    "                for AS in [\"SA\", \"WA\"]:\n",
    "                    for VZ in [\"\", \"_VZ\"]:\n",
    "                        \n",
    "                        # line + color settings\n",
    "                        color = \"blue\" if AS == \"SA\" else \"red\"\n",
    "                        \n",
    "                        # what are the values at play for this variant?\n",
    "                        vals = master.query((f\"dataset == '{dataset}' and model == '{model}' and \"\n",
    "                                             f\"K == {K} and weight_scheme == '{weight_scheme}'\"))\\\n",
    "                        [f\"L1_{AS}{VZ}\"].values\n",
    "                        \n",
    "                        # make a point scatter with the mean, and then error bars for the min & max.\n",
    "                        ax[i // 4, i % 4].scatter(x=[(2*j) + [-1/2, -1/6, +1/6, +1/2][counter]], \n",
    "                                                  y=[np.mean(vals)], color=color, s=12)\n",
    "                        eb = ax[i // 4, i % 4].errorbar(x=[(2*j) + [-1/2, -1/6, +1/6, +1/2][counter]], \n",
    "                                                        y=[np.mean(vals)],\n",
    "                                                        yerr=[[np.mean(vals) - np.min(vals)], \n",
    "                                                              [np.max(vals) - np.mean(vals)]], \n",
    "                                                        color=color, capsize=3)\n",
    "                        if VZ == \"_VZ\":\n",
    "                            eb[-1][0].set_linestyle('--')\n",
    "                        \n",
    "                        # increment our counter\n",
    "                        counter += 1\n",
    "                        \n",
    "                        # I just want to sanity check\n",
    "                        if (K == 64) and (AS == \"SA\") and (VZ == \"\"):\n",
    "                            if np.mean(vals) < np.mean(base_vals):\n",
    "                                success += 1\n",
    "            \n",
    "            # more beautifying\n",
    "            ax[i // 4, i % 4].set_xticks([0, 2, 4, 6])\n",
    "            ax[i // 4, i % 4].set_xticklabels([\"K=1\", \"K=4\", \"K=16\", \"K=64\"])\n",
    "            ax[i // 4, i % 4].tick_params(\"both\", labelsize=13.5)\n",
    "        \n",
    "        # custom legend\n",
    "        custom_lines = [Line2D([0], [0], color=\"blue\", linestyle=None, \n",
    "                               label=\"Simple Average\"),\n",
    "                        Line2D([0], [0], color=\"blue\", linestyle=\"--\", \n",
    "                               label='Simple Average + Voting-Based Zeroing'),\n",
    "                        Line2D([0], [0], color=\"red\", linestyle=None, \n",
    "                               label=\"Weighted Average\"),\n",
    "                        Line2D([0], [0], color=\"red\", linestyle='--', \n",
    "                               label=\"Weighted Average + Voting-Based Zeroing\"),\n",
    "                        Patch(facecolor=\"green\", alpha=0.5, label=model),\n",
    "                        Line2D([0], [0], color=\"green\", linestyle=None, \n",
    "                               label=f\"{model} (Mean)\")]\n",
    "        fig.legend(handles=custom_lines, loc=\"lower center\", ncol=3, fontsize=13.5, bbox_to_anchor=(0.5, -0.075))\n",
    "        \n",
    "        # for our logging purposes\n",
    "        print(success)\n",
    "        \n",
    "        # beautify\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"figures/errorbars/model={model}_ws={weight_scheme}_L1-ROP.png\", \n",
    "                    facecolor=\"white\", bbox_inches=\"tight\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8415daa8",
   "metadata": {},
   "source": [
    "# Error Bars for Final Test Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511ce255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# go thru each combination of base model + weight_scheme\n",
    "for model in [\"PAC\", \"FSOL\"]:\n",
    "    for weight_scheme in [\"dense\", \"exp-dense\"]:\n",
    "        \n",
    "        # start our figure\n",
    "        fig, ax = plt.subplots(4, 4, dpi=200, figsize=(14, 12))\n",
    "        \n",
    "        # counters to see how many times we have mean higher test accuracy than baseline + oracle.\n",
    "        success, oracle_success = 0, 0\n",
    "        \n",
    "        # go thru each of our datasets\n",
    "        for i, dataset in enumerate(dataset_descs.keys()):\n",
    "            \n",
    "            # beautify our subplot immediately\n",
    "            ax[i // 4, i % 4].grid()\n",
    "            ax[i // 4, i % 4].set_title(dataset_descs[dataset], fontsize=15)\n",
    "            \n",
    "            # set to store our base values for instantaneous + cummax\n",
    "            base_vals, oracle_vals = [], []\n",
    "            \n",
    "            # load in the instantaneous test accuracies for seed=0\n",
    "            if model == \"PAC\":\n",
    "\n",
    "                # immediately load in the best hyperparameters for this dataset + model\n",
    "                log10Cerr = pd.read_csv(\"base_variants/PAC_hparams.csv\")\\\n",
    "                .query(f\"dataset == '{dataset}'\")[[\"log10Cerr\"]].values[0,0]\n",
    "                log10Cerr = int(log10Cerr)\n",
    "\n",
    "                # load in the file + get the values that we should be plotting\n",
    "                for seed in range(5):\n",
    "                    logs_inst = pd.read_csv(f\"../hparam_tuning/results/{model}/{dataset}/model={model}_log10Cerr={log10Cerr}_seed={seed}_metrics.csv\")\n",
    "                    base_vals.append(logs_inst[\"inst_test-set-acc\"].values[-1])\n",
    "                    oracle_vals.append(logs_inst[\"inst_test-set-acc\"].max())\n",
    "                    \n",
    "            elif model == \"FSOL\":\n",
    "\n",
    "                # immediately load in the best hyperparameters for this dataset + model\n",
    "                log2eta, log10lmbda = pd.read_csv(\"base_variants/FSOL_hparams.csv\")\\\n",
    "                .query(f\"dataset == '{dataset}'\")[[\"log2eta\", \"log10lmbda\"]].values[0]\n",
    "                log2eta, log10lmbda = log2eta, log10lmbda\n",
    "\n",
    "                # load in the file + get the values that we should be plotting\n",
    "                for seed in range(5):\n",
    "                    logs_inst = pd.read_csv(f\"../hparam_tuning/results/{model}/{dataset}/model={model}_log2eta={log2eta}_log10lmbda={log10lmbda}_seed={seed}_metrics.csv\")\n",
    "                    base_vals.append(logs_inst[\"inst_test-set-acc\"].values[-1])\n",
    "                    oracle_vals.append(logs_inst[\"inst_test-set-acc\"].max())\n",
    "        \n",
    "            # for test accuracy, let's do cummax Oracle as the colored bar\n",
    "            ax[i // 4, i % 4].axhline(y=np.mean(oracle_vals), color=\"green\")\n",
    "            ax[i // 4, i % 4].fill_between([0-1/2, 2, 3, 8+1/2], [np.min(oracle_vals)] * 4, [np.max(oracle_vals)] * 4, \n",
    "                                           alpha=0.5, color=\"green\")\n",
    "            \n",
    "            # for test accuracy, let's do the instantaneous as ITS OWN ERROR BAR!\n",
    "            ax[i // 4, i % 4].scatter(x=[0], y=[np.mean(base_vals)], color=\"black\", s=12)\n",
    "            eb = ax[i // 4, i % 4].errorbar(x=[0], y=[np.mean(base_vals)], \n",
    "                                            yerr=[[np.mean(base_vals) - np.min(base_vals)], \n",
    "                                                  [np.max(base_vals) - np.mean(base_vals)]], \n",
    "                                            color=\"black\", capsize=3)\n",
    "            \n",
    "            # let's iterate thru our variants\n",
    "            for j, K in enumerate([1, 4, 16, 64]):\n",
    "                \n",
    "                # create a counter to help us out\n",
    "                counter = 0\n",
    "                \n",
    "                # plot all four error bars for this value of K\n",
    "                for AS in [\"SA\", \"WA\"]:\n",
    "                    for VZ in [\"\", \"_VZ\"]:\n",
    "                        \n",
    "                        # line + color settings\n",
    "                        color = \"blue\" if AS == \"SA\" else \"red\"\n",
    "                        \n",
    "                        # what are the values at play for this variant?\n",
    "                        vals = master.query((f\"dataset == '{dataset}' and model == '{model}' and \"\n",
    "                                             f\"K == {K} and weight_scheme == '{weight_scheme}'\"))\\\n",
    "                        [f\"fin_test_acc_{AS}{VZ}\"].values\n",
    "                        \n",
    "                        # make a point scatter with the mean, and then error bars for the min & max.\n",
    "                        ax[i // 4, i % 4].scatter(x=[(2*(j+1)) + [-1/2, -1/6, +1/6, +1/2][counter]], \n",
    "                                                  y=[np.mean(vals)], color=color, s=12)\n",
    "                        eb = ax[i // 4, i % 4].errorbar(x=[(2*(j+1)) + [-1/2, -1/6, +1/6, +1/2][counter]], \n",
    "                                                        y=[np.mean(vals)],\n",
    "                                                        yerr=[[np.mean(vals) - np.min(vals)], \n",
    "                                                              [np.max(vals) - np.mean(vals)]], \n",
    "                                                        color=color, capsize=3)\n",
    "                        if VZ == \"_VZ\":\n",
    "                            eb[-1][0].set_linestyle('--')\n",
    "                        \n",
    "                        # increment our counter\n",
    "                        counter += 1\n",
    "                        \n",
    "                        # I just want to sanity check\n",
    "                        if (K == 64) and (AS == \"SA\") and (VZ == \"\"):\n",
    "                            if np.mean(vals) > np.mean(base_vals):\n",
    "                                success += 1\n",
    "                            if np.mean(vals) > np.mean(oracle_vals):\n",
    "                                oracle_success += 1\n",
    "            \n",
    "            # more beautifying\n",
    "            ax[i // 4, i % 4].set_xticks([0, 2, 4, 6, 8])\n",
    "            ax[i // 4, i % 4].set_xticklabels([model, \"K=1\", \"K=4\", \"K=16\", \"K=64\"])\n",
    "            ax[i // 4, i % 4].tick_params(\"both\", labelsize=12)\n",
    "        \n",
    "        # custom legend\n",
    "        custom_lines = [Line2D([0], [0], color=\"blue\", linestyle=None, \n",
    "                               label=\"Simple Average\"),\n",
    "                        Line2D([0], [0], color=\"blue\", linestyle=\"--\", \n",
    "                               label='Simple Average + Voting-Based Zeroing'),\n",
    "                        Line2D([0], [0], color=\"red\", linestyle=None, \n",
    "                               label=\"Weighted Average\"),\n",
    "                        Line2D([0], [0], color=\"red\", linestyle='--', \n",
    "                               label=\"Weighted Average + Voting-Based Zeroing\"),\n",
    "                        Patch(facecolor=\"green\", alpha=0.5, label=\"Oracle\"),\n",
    "                        Line2D([0], [0], color=\"green\", linestyle=None, \n",
    "                               label=f\"Oracle (Mean)\"),\n",
    "                        Line2D([0], [0], color=\"black\", linestyle=None, \n",
    "                               label=model)]\n",
    "        fig.legend(handles=custom_lines, loc=\"lower center\", ncol=4, fontsize=12, bbox_to_anchor=(0.5, -0.075))\n",
    "        \n",
    "        print(f\"{model}, {weight_scheme}: Success={success}, Oracle Success={oracle_success}\")\n",
    "        \n",
    "        # beautify\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"figures/errorbars/model={model}_ws={weight_scheme}_final-test-acc.png\", \n",
    "                    facecolor=\"white\", bbox_inches=\"tight\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c3b3270",
   "metadata": {},
   "source": [
    "# Main Text ROP Figure - PAC + 3 Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bf9bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's do PAC and three datasets\n",
    "model, exhibition_datasets = \"PAC\", [\"avazu-app_binary_sparse\", \"mnist8-4+9_binary_sparse\", \"news20_binary_sparse\"]\n",
    "weight_scheme = \"dense\"\n",
    "\n",
    "# create our subplots\n",
    "fig, ax = plt.subplots(1, 3, dpi=200, figsize=(14*(3/4), 12/4))\n",
    "\n",
    "# counter for successes on each of these datasets\n",
    "success = 0\n",
    "        \n",
    "# go thru each of our datasets\n",
    "for i, dataset in enumerate(exhibition_datasets):\n",
    "\n",
    "    # beautify our subplot immediately\n",
    "    ax[i].grid()\n",
    "    ax[i].set_title(dataset_descs[dataset], fontsize=15)\n",
    "\n",
    "    # set to store our base values\n",
    "    base_vals = []\n",
    "\n",
    "    # load in the instantaneous test accuracies for seed=0\n",
    "    if model == \"PAC\":\n",
    "\n",
    "        # immediately load in the best hyperparameters for this dataset + model\n",
    "        log10Cerr = pd.read_csv(\"base_variants/PAC_hparams.csv\")\\\n",
    "        .query(f\"dataset == '{dataset}'\")[[\"log10Cerr\"]].values[0,0]\n",
    "        log10Cerr = int(log10Cerr)\n",
    "\n",
    "        # load in the file + get the values that we should be plotting\n",
    "        for seed in range(5):\n",
    "            logs_inst = pd.read_csv(f\"../hparam_tuning/results/{model}/{dataset}/model={model}_log10Cerr={log10Cerr}_seed={seed}_metrics.csv\")\n",
    "            base_vals.append((logs_inst[\"inst_test-set-acc\"][1:].cummax().values - logs_inst[\"inst_test-set-acc\"][1:].values).mean())\n",
    "\n",
    "    elif model == \"FSOL\":\n",
    "\n",
    "        # immediately load in the best hyperparameters for this dataset + model\n",
    "        log2eta, log10lmbda = pd.read_csv(\"base_variants/FSOL_hparams.csv\")\\\n",
    "        .query(f\"dataset == '{dataset}'\")[[\"log2eta\", \"log10lmbda\"]].values[0]\n",
    "        log2eta, log10lmbda = log2eta, log10lmbda\n",
    "\n",
    "        # load in the file + get the values that we should be plotting\n",
    "        for seed in range(5):\n",
    "            logs_inst = pd.read_csv(f\"../hparam_tuning/results/{model}/{dataset}/model={model}_log2eta={log2eta}_log10lmbda={log10lmbda}_seed={seed}_metrics.csv\")\n",
    "            base_vals.append((logs_inst[\"inst_test-set-acc\"][1:].cummax().values - logs_inst[\"inst_test-set-acc\"][1:].values).mean())\n",
    "\n",
    "    # put a confidence band in light green + line at the mean (MIN + MAX)\n",
    "    ax[i].axhline(y=np.mean(base_vals), color=\"green\")\n",
    "    ax[i].fill_between([0-1/2, 2, 3, 6+1/2], [np.min(base_vals)] * 4, [np.max(base_vals)] * 4, \n",
    "                                   alpha=0.5, color=\"green\")\n",
    "\n",
    "    # let's showing up our variants\n",
    "    for j, K in enumerate([1, 4, 16, 64]):\n",
    "\n",
    "        # create a counter to help us out\n",
    "        counter = 0\n",
    "\n",
    "        # plot all four error bars for this value of K\n",
    "        for AS in [\"SA\", \"WA\"]:\n",
    "            for VZ in [\"\", \"_VZ\"]:\n",
    "\n",
    "                # line + color settings\n",
    "                color = \"blue\" if AS == \"SA\" else \"red\"\n",
    "\n",
    "                # what are the values at play for this variant?\n",
    "                vals = master.query((f\"dataset == '{dataset}' and model == '{model}' and \"\n",
    "                                     f\"K == {K} and weight_scheme == '{weight_scheme}'\"))\\\n",
    "                [f\"L1_{AS}{VZ}\"].values\n",
    "\n",
    "                # make a point scatter with the mean, and then error bars for the min & max.\n",
    "                ax[i].scatter(x=[(2*j) + [-1/2, -1/6, +1/6, +1/2][counter]], \n",
    "                                          y=[np.mean(vals)], color=color, s=12)\n",
    "                eb = ax[i].errorbar(x=[(2*j) + [-1/2, -1/6, +1/6, +1/2][counter]], \n",
    "                                                y=[np.mean(vals)],\n",
    "                                                yerr=[[np.mean(vals) - np.min(vals)], \n",
    "                                                      [np.max(vals) - np.mean(vals)]], \n",
    "                                                color=color, capsize=3)\n",
    "                if VZ == \"_VZ\":\n",
    "                    eb[-1][0].set_linestyle('--')\n",
    "\n",
    "                # increment our counter\n",
    "                counter += 1\n",
    "\n",
    "                # I just want to sanity check\n",
    "                if (K == 64) and (AS == \"SA\") and (VZ == \"\"):\n",
    "                    if np.mean(vals) < np.mean(base_vals):\n",
    "                        success += 1\n",
    "\n",
    "    # more beautifying\n",
    "    ax[i].set_xticks([0, 2, 4, 6])\n",
    "    ax[i].set_xticklabels([\"K=1\", \"K=4\", \"K=16\", \"K=64\"])\n",
    "    ax[i].tick_params(\"both\", labelsize=13.5)\n",
    "\n",
    "# custom legend\n",
    "custom_lines = [Line2D([0], [0], color=\"blue\", linestyle=None, \n",
    "                       label=\"Simple Average\"),\n",
    "                Line2D([0], [0], color=\"blue\", linestyle=\"--\", \n",
    "                       label='Simple Average + Voting-Based Zeroing'),\n",
    "                Line2D([0], [0], color=\"red\", linestyle=None, \n",
    "                       label=\"Weighted Average\"),\n",
    "                Line2D([0], [0], color=\"red\", linestyle='--', \n",
    "                       label=\"Weighted Average + Voting-Based Zeroing\"),\n",
    "                Patch(facecolor=\"green\", alpha=0.5, label=model),\n",
    "                Line2D([0], [0], color=\"green\", linestyle=None, \n",
    "                       label=f\"{model} (Mean)\")]\n",
    "fig.legend(handles=custom_lines, loc=\"lower center\", ncol=3, fontsize=10, bbox_to_anchor=(0.5, -0.15))\n",
    "\n",
    "# for our logging purposes\n",
    "print(success)\n",
    "\n",
    "# beautify\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"figures/exhibition-ROP.png\", \n",
    "            facecolor=\"white\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7620f5",
   "metadata": {},
   "source": [
    "# Main Text Final Test Accuracy Figure - FSOL + 3 Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cbb485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's do FSOL and three datasets\n",
    "model, exhibition_datasets = \"FSOL\", [\"avazu-site_binary_sparse\", \"kdd2010-a_binary_sparse\", \"sst2_binary_sparse\"]\n",
    "weight_scheme = \"dense\"\n",
    "\n",
    "# counters to see how many times we have mean higher test accuracy than baseline + oracle.\n",
    "success, oracle_success = 0, 0\n",
    "\n",
    "# create our subplots\n",
    "fig, ax = plt.subplots(1, 3, dpi=200, figsize=(14*(3/4), 12/4))\n",
    "\n",
    "# go thru each of our datasets\n",
    "for i, dataset in enumerate(exhibition_datasets):\n",
    "\n",
    "    # beautify our subplot immediately\n",
    "    ax[i].grid()\n",
    "    ax[i].set_title(dataset_descs[dataset], fontsize=15)\n",
    "\n",
    "    # set to store our base values for instantaneous + cummax\n",
    "    base_vals, oracle_vals = [], []\n",
    "\n",
    "    # load in the instantaneous test accuracies for seed=0\n",
    "    if model == \"PAC\":\n",
    "\n",
    "        # immediately load in the best hyperparameters for this dataset + model\n",
    "        log10Cerr = pd.read_csv(\"base_variants/PAC_hparams.csv\")\\\n",
    "        .query(f\"dataset == '{dataset}'\")[[\"log10Cerr\"]].values[0,0]\n",
    "        log10Cerr = int(log10Cerr)\n",
    "\n",
    "        # load in the file + get the values that we should be plotting\n",
    "        for seed in range(5):\n",
    "            logs_inst = pd.read_csv(f\"../hparam_tuning/results/{model}/{dataset}/model={model}_log10Cerr={log10Cerr}_seed={seed}_metrics.csv\")\n",
    "            base_vals.append(logs_inst[\"inst_test-set-acc\"].values[-1])\n",
    "            oracle_vals.append(logs_inst[\"inst_test-set-acc\"].max())\n",
    "\n",
    "    elif model == \"FSOL\":\n",
    "\n",
    "        # immediately load in the best hyperparameters for this dataset + model\n",
    "        log2eta, log10lmbda = pd.read_csv(\"base_variants/FSOL_hparams.csv\")\\\n",
    "        .query(f\"dataset == '{dataset}'\")[[\"log2eta\", \"log10lmbda\"]].values[0]\n",
    "        log2eta, log10lmbda = log2eta, log10lmbda\n",
    "\n",
    "        # load in the file + get the values that we should be plotting\n",
    "        for seed in range(5):\n",
    "            logs_inst = pd.read_csv(f\"../hparam_tuning/results/{model}/{dataset}/model={model}_log2eta={log2eta}_log10lmbda={log10lmbda}_seed={seed}_metrics.csv\")\n",
    "            base_vals.append(logs_inst[\"inst_test-set-acc\"].values[-1])\n",
    "            oracle_vals.append(logs_inst[\"inst_test-set-acc\"].max())\n",
    "\n",
    "    # for test accuracy, let's do cummax Oracle as the colored bar\n",
    "    ax[i].axhline(y=np.mean(oracle_vals), color=\"green\")\n",
    "    ax[i].fill_between([0-1/2, 2, 3, 8+1/2], [np.min(oracle_vals)] * 4, [np.max(oracle_vals)] * 4, \n",
    "                                   alpha=0.5, color=\"green\")\n",
    "\n",
    "    # for test accuracy, let's do the instantaneous as ITS OWN ERROR BAR!\n",
    "    ax[i].scatter(x=[0], y=[np.mean(base_vals)], color=\"black\", s=12)\n",
    "    eb = ax[i].errorbar(x=[0], y=[np.mean(base_vals)], \n",
    "                                    yerr=[[np.mean(base_vals) - np.min(base_vals)], \n",
    "                                          [np.max(base_vals) - np.mean(base_vals)]], \n",
    "                                    color=\"black\", capsize=3)\n",
    "\n",
    "    # let's iterate thru our variants\n",
    "    for j, K in enumerate([1, 4, 16, 64]):\n",
    "\n",
    "        # create a counter to help us out\n",
    "        counter = 0\n",
    "\n",
    "        # plot all four error bars for this value of K\n",
    "        for AS in [\"SA\", \"WA\"]:\n",
    "            for VZ in [\"\", \"_VZ\"]:\n",
    "\n",
    "                # line + color settings\n",
    "                color = \"blue\" if AS == \"SA\" else \"red\"\n",
    "\n",
    "                # what are the values at play for this variant?\n",
    "                vals = master.query((f\"dataset == '{dataset}' and model == '{model}' and \"\n",
    "                                     f\"K == {K} and weight_scheme == '{weight_scheme}'\"))\\\n",
    "                [f\"fin_test_acc_{AS}{VZ}\"].values\n",
    "\n",
    "                # make a point scatter with the mean, and then error bars for the min & max.\n",
    "                ax[i].scatter(x=[(2*(j+1)) + [-1/2, -1/6, +1/6, +1/2][counter]], \n",
    "                                          y=[np.mean(vals)], color=color, s=12)\n",
    "                eb = ax[i].errorbar(x=[(2*(j+1)) + [-1/2, -1/6, +1/6, +1/2][counter]], \n",
    "                                                y=[np.mean(vals)],\n",
    "                                                yerr=[[np.mean(vals) - np.min(vals)], \n",
    "                                                      [np.max(vals) - np.mean(vals)]], \n",
    "                                                color=color, capsize=3)\n",
    "                if VZ == \"_VZ\":\n",
    "                    eb[-1][0].set_linestyle('--')\n",
    "\n",
    "                # increment our counter\n",
    "                counter += 1\n",
    "\n",
    "                # I just want to sanity check\n",
    "                if (K == 64) and (AS == \"SA\") and (VZ == \"\"):\n",
    "                    if np.mean(vals) > np.mean(base_vals):\n",
    "                        success += 1\n",
    "                    if np.mean(vals) > np.mean(oracle_vals):\n",
    "                        oracle_success += 1\n",
    "\n",
    "    # more beautifying\n",
    "    ax[i].set_xticks([0, 2, 4, 6, 8])\n",
    "    ax[i].set_xticklabels([model, \"K=1\", \"K=4\", \"K=16\", \"K=64\"])\n",
    "    ax[i].tick_params(\"both\", labelsize=12)\n",
    "\n",
    "# custom legend\n",
    "custom_lines = [Line2D([0], [0], color=\"blue\", linestyle=None, \n",
    "                       label=\"Simple Average\"),\n",
    "                Line2D([0], [0], color=\"blue\", linestyle=\"--\", \n",
    "                       label='Simple Average + Voting-Based Zeroing'),\n",
    "                Line2D([0], [0], color=\"red\", linestyle=None, \n",
    "                       label=\"Weighted Average\"),\n",
    "                Line2D([0], [0], color=\"red\", linestyle='--', \n",
    "                       label=\"Weighted Average + Voting-Based Zeroing\"),\n",
    "                Patch(facecolor=\"green\", alpha=0.5, label=\"Oracle\"),\n",
    "                Line2D([0], [0], color=\"green\", linestyle=None, \n",
    "                       label=f\"Oracle (Mean)\"),\n",
    "                Line2D([0], [0], color=\"black\", linestyle=None, \n",
    "                       label=model)]\n",
    "fig.legend(handles=custom_lines, loc=\"lower center\", ncol=4, fontsize=10, bbox_to_anchor=(0.5, -0.15))\n",
    "\n",
    "print(f\"{model}, {weight_scheme}: Success={success}, Oracle Success={oracle_success}\")\n",
    "\n",
    "# beautify\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"figures/exhibition_final-test-acc.png\", \n",
    "            facecolor=\"white\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a2858f",
   "metadata": {},
   "source": [
    "# Error Bars for Final Sparsity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe62c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# go thru each combination of base model + weight_scheme\n",
    "for model in [\"PAC\", \"FSOL\"]:\n",
    "    for weight_scheme in [\"dense\", \"exp-dense\"]:\n",
    "        \n",
    "        # start our figure\n",
    "        fig, ax = plt.subplots(4, 4, dpi=200, figsize=(14, 12))\n",
    "        \n",
    "        # go thru each of our datasets\n",
    "        for i, dataset in enumerate(dataset_descs.keys()):\n",
    "            \n",
    "            # beautify our subplot immediately\n",
    "            ax[i // 4, i % 4].grid()\n",
    "            ax[i // 4, i % 4].set_title(dataset_descs[dataset], fontsize=15)\n",
    "            \n",
    "            # set to store our base values for instantaneous. NO CUMMAX CONCEPT FOR SPARSITY!\n",
    "            base_vals = []\n",
    "            \n",
    "            # load in the instantaneous test accuracies for seed=0\n",
    "            if model == \"PAC\":\n",
    "\n",
    "                # immediately load in the best hyperparameters for this dataset + model\n",
    "                log10Cerr = pd.read_csv(\"base_variants/PAC_hparams.csv\")\\\n",
    "                .query(f\"dataset == '{dataset}'\")[[\"log10Cerr\"]].values[0,0]\n",
    "                log10Cerr = int(log10Cerr)\n",
    "\n",
    "                # load in the file + get the values that we should be plotting\n",
    "                for seed in range(5):\n",
    "                    logs_inst = pd.read_csv(f\"../hparam_tuning/results/{model}/{dataset}/model={model}_log10Cerr={log10Cerr}_seed={seed}_metrics.csv\")\n",
    "                    base_vals.append(logs_inst[\"inst_sparsity\"].values[-1])\n",
    "                    \n",
    "            elif model == \"FSOL\":\n",
    "\n",
    "                # immediately load in the best hyperparameters for this dataset + model\n",
    "                log2eta, log10lmbda = pd.read_csv(\"base_variants/FSOL_hparams.csv\")\\\n",
    "                .query(f\"dataset == '{dataset}'\")[[\"log2eta\", \"log10lmbda\"]].values[0]\n",
    "                log2eta, log10lmbda = log2eta, log10lmbda\n",
    "\n",
    "                # load in the file + get the values that we should be plotting\n",
    "                for seed in range(5):\n",
    "                    logs_inst = pd.read_csv(f\"../hparam_tuning/results/{model}/{dataset}/model={model}_log2eta={log2eta}_log10lmbda={log10lmbda}_seed={seed}_metrics.csv\")\n",
    "                    base_vals.append(logs_inst[\"inst_sparsity\"].values[-1])\n",
    "                    \n",
    "            # for test accuracy, let's do the instantaneous as ITS OWN ERROR BAR!\n",
    "            ax[i // 4, i % 4].scatter(x=[0], y=[np.mean(base_vals)], color=\"black\", s=12)\n",
    "            eb = ax[i // 4, i % 4].errorbar(x=[0], y=[np.mean(base_vals)], \n",
    "                                            yerr=[[np.maximum(np.mean(base_vals) - np.min(base_vals), 0)], \n",
    "                                                  [np.maximum(np.max(base_vals) - np.mean(base_vals), 0)]], \n",
    "                                            color=\"black\", capsize=3)\n",
    "            \n",
    "            # let's iterate thru our variants\n",
    "            for j, K in enumerate([1, 4, 16, 64]):\n",
    "                \n",
    "                # create a counter to help us out\n",
    "                counter = 0\n",
    "                \n",
    "                # plot all four error bars for this value of K\n",
    "                for AS in [\"SA\", \"WA\"]:\n",
    "                    for VZ in [\"\", \"_VZ\"]:\n",
    "                        \n",
    "                        # line + color settings\n",
    "                        color = \"blue\" if AS == \"SA\" else \"red\"\n",
    "                        \n",
    "                        # what are the values at play for this variant?\n",
    "                        vals = master.query((f\"dataset == '{dataset}' and model == '{model}' and \"\n",
    "                                             f\"K == {K} and weight_scheme == '{weight_scheme}'\"))\\\n",
    "                        [f\"fin_sparsity_{AS}{VZ}\"].values\n",
    "                        \n",
    "                        # make a point scatter with the mean, and then error bars for the min & max.\n",
    "                        ax[i // 4, i % 4].scatter(x=[(2*(j+1)) + [-1/2, -1/6, +1/6, +1/2][counter]], \n",
    "                                                  y=[np.mean(vals)], color=color, s=12)\n",
    "                        eb = ax[i // 4, i % 4].errorbar(x=[(2*(j+1)) + [-1/2, -1/6, +1/6, +1/2][counter]], \n",
    "                                                        y=[np.mean(vals)],\n",
    "                                                        yerr=[[np.maximum(np.mean(vals) - np.min(vals), 0)], \n",
    "                                                              [np.maximum(np.max(vals) - np.mean(vals), 0)]], \n",
    "                                                        color=color, capsize=3)\n",
    "                        if VZ == \"_VZ\":\n",
    "                            eb[-1][0].set_linestyle('--')\n",
    "                        \n",
    "                        # increment our counter\n",
    "                        counter += 1\n",
    "            \n",
    "            # more beautifying\n",
    "            ax[i // 4, i % 4].set_xticks([0, 2, 4, 6, 8])\n",
    "            ax[i // 4, i % 4].set_xticklabels([model, \"K=1\", \"K=4\", \"K=16\", \"K=64\"])\n",
    "            ax[i // 4, i % 4].tick_params(\"both\", labelsize=12)\n",
    "        \n",
    "        # custom legend\n",
    "        custom_lines = [Line2D([0], [0], color=\"blue\", linestyle=None, \n",
    "                               label=\"Simple Average\"),\n",
    "                        Line2D([0], [0], color=\"blue\", linestyle=\"--\", \n",
    "                               label='Simple Average + Voting-Based Zeroing'),\n",
    "                        Line2D([0], [0], color=\"red\", linestyle=None, \n",
    "                               label=\"Weighted Average\"),\n",
    "                        Line2D([0], [0], color=\"red\", linestyle='--', \n",
    "                               label=\"Weighted Average + Voting-Based Zeroing\"),\n",
    "                        Line2D([0], [0], color=\"black\", linestyle=None, \n",
    "                               label=model)]\n",
    "        fig.legend(handles=custom_lines, loc=\"lower center\", ncol=3, fontsize=12, bbox_to_anchor=(0.5, -0.075))\n",
    "        \n",
    "        # beautify\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"figures/errorbars/model={model}_ws={weight_scheme}_sparsity.png\", \n",
    "                    facecolor=\"white\", bbox_inches=\"tight\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e874c01",
   "metadata": {},
   "source": [
    "# Main Text Final Sparsity Figure - FSOL + 3 Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d8c878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's do FSOL and three datasets\n",
    "model, exhibition_datasets = \"FSOL\", [\"avazu-site_binary_sparse\", \"kdd2010-a_binary_sparse\", \"sst2_binary_sparse\"]\n",
    "weight_scheme = \"dense\"\n",
    "\n",
    "# create our subplots\n",
    "fig, ax = plt.subplots(1, 3, dpi=200, figsize=(14*(3/4), 12/4))\n",
    "\n",
    "# go thru each of our datasets\n",
    "for i, dataset in enumerate(exhibition_datasets):\n",
    "\n",
    "    # beautify our subplot immediately\n",
    "    ax[i].grid()\n",
    "    ax[i].set_title(dataset_descs[dataset], fontsize=15)\n",
    "\n",
    "    # set to store our base values for instantaneous. NO CUMMAX CONCEPT FOR SPARSITY!\n",
    "    base_vals = []\n",
    "\n",
    "    # load in the instantaneous test accuracies for seed=0\n",
    "    if model == \"PAC\":\n",
    "\n",
    "        # immediately load in the best hyperparameters for this dataset + model\n",
    "        log10Cerr = pd.read_csv(\"base_variants/PAC_hparams.csv\")\\\n",
    "        .query(f\"dataset == '{dataset}'\")[[\"log10Cerr\"]].values[0,0]\n",
    "        log10Cerr = int(log10Cerr)\n",
    "\n",
    "        # load in the file + get the values that we should be plotting\n",
    "        for seed in range(5):\n",
    "            logs_inst = pd.read_csv(f\"../hparam_tuning/results/{model}/{dataset}/model={model}_log10Cerr={log10Cerr}_seed={seed}_metrics.csv\")\n",
    "            base_vals.append(logs_inst[\"inst_sparsity\"].values[-1])\n",
    "\n",
    "    elif model == \"FSOL\":\n",
    "\n",
    "        # immediately load in the best hyperparameters for this dataset + model\n",
    "        log2eta, log10lmbda = pd.read_csv(\"base_variants/FSOL_hparams.csv\")\\\n",
    "        .query(f\"dataset == '{dataset}'\")[[\"log2eta\", \"log10lmbda\"]].values[0]\n",
    "        log2eta, log10lmbda = log2eta, log10lmbda\n",
    "\n",
    "        # load in the file + get the values that we should be plotting\n",
    "        for seed in range(5):\n",
    "            logs_inst = pd.read_csv(f\"../hparam_tuning/results/{model}/{dataset}/model={model}_log2eta={log2eta}_log10lmbda={log10lmbda}_seed={seed}_metrics.csv\")\n",
    "            base_vals.append(logs_inst[\"inst_sparsity\"].values[-1])\n",
    "\n",
    "    # for test accuracy, let's do the instantaneous as ITS OWN ERROR BAR!\n",
    "    ax[i].scatter(x=[0], y=[np.mean(base_vals)], color=\"black\", s=12)\n",
    "    eb = ax[i].errorbar(x=[0], y=[np.mean(base_vals)], \n",
    "                                    yerr=[[np.maximum(np.mean(base_vals) - np.min(base_vals), 0)], \n",
    "                                          [np.maximum(np.max(base_vals) - np.mean(base_vals), 0)]], \n",
    "                                    color=\"black\", capsize=3)\n",
    "\n",
    "    # let's iterate thru our variants\n",
    "    for j, K in enumerate([1, 4, 16, 64]):\n",
    "\n",
    "        # create a counter to help us out\n",
    "        counter = 0\n",
    "\n",
    "        # plot all four error bars for this value of K\n",
    "        for AS in [\"SA\", \"WA\"]:\n",
    "            for VZ in [\"\", \"_VZ\"]:\n",
    "\n",
    "                # line + color settings\n",
    "                color = \"blue\" if AS == \"SA\" else \"red\"\n",
    "\n",
    "                # what are the values at play for this variant?\n",
    "                vals = master.query((f\"dataset == '{dataset}' and model == '{model}' and \"\n",
    "                                     f\"K == {K} and weight_scheme == '{weight_scheme}'\"))\\\n",
    "                [f\"fin_sparsity_{AS}{VZ}\"].values\n",
    "\n",
    "                # make a point scatter with the mean, and then error bars for the min & max.\n",
    "                ax[i].scatter(x=[(2*(j+1)) + [-1/2, -1/6, +1/6, +1/2][counter]], \n",
    "                                          y=[np.mean(vals)], color=color, s=12)\n",
    "                eb = ax[i].errorbar(x=[(2*(j+1)) + [-1/2, -1/6, +1/6, +1/2][counter]], \n",
    "                                                y=[np.mean(vals)],\n",
    "                                                yerr=[[np.maximum(np.mean(vals) - np.min(vals), 0)], \n",
    "                                                      [np.maximum(np.max(vals) - np.mean(vals), 0)]], \n",
    "                                                color=color, capsize=3)\n",
    "                if VZ == \"_VZ\":\n",
    "                    eb[-1][0].set_linestyle('--')\n",
    "\n",
    "                # increment our counter\n",
    "                counter += 1\n",
    "\n",
    "    # more beautifying\n",
    "    ax[i].set_xticks([0, 2, 4, 6, 8])\n",
    "    ax[i].set_xticklabels([model, \"K=1\", \"K=4\", \"K=16\", \"K=64\"])\n",
    "    ax[i].tick_params(\"both\", labelsize=12)\n",
    "\n",
    "# custom legend\n",
    "custom_lines = [Line2D([0], [0], color=\"blue\", linestyle=None, \n",
    "                       label=\"Simple Average\"),\n",
    "                Line2D([0], [0], color=\"blue\", linestyle=\"--\", \n",
    "                       label='Simple Average + Voting-Based Zeroing'),\n",
    "                Line2D([0], [0], color=\"red\", linestyle=None, \n",
    "                       label=\"Weighted Average\"),\n",
    "                Line2D([0], [0], color=\"red\", linestyle='--', \n",
    "                       label=\"Weighted Average + Voting-Based Zeroing\"),\n",
    "                Line2D([0], [0], color=\"black\", linestyle=None, \n",
    "                       label=model)]\n",
    "fig.legend(handles=custom_lines, loc=\"lower center\", ncol=3, fontsize=10, bbox_to_anchor=(0.5, -0.15))\n",
    "\n",
    "# beautify\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"figures/exhibition-sparsity.png\", \n",
    "            facecolor=\"white\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a8ac85",
   "metadata": {},
   "source": [
    "# Process Some Logs on Baseline Methods (allows derive oracle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c415a882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create our dataframe\n",
    "baseline_logs = pd.DataFrame(data=None, columns=[\"dataset\", \"model\", \"seed\", \"fin_test_acc_inst\", \n",
    "                                                 \"fin_test_hinge_inst\", \"fin_sparsity_inst\", \"L1_inst\"])\n",
    "\n",
    "# go thru each model + dataset + seed\n",
    "for model in [\"PAC\", \"FSOL\"]:\n",
    "    for dataset in dataset_descs.keys():\n",
    "        for seed in range(5):\n",
    "            \n",
    "            # load in the relevant log files\n",
    "            if model == \"PAC\":\n",
    "\n",
    "                # immediately load in the best hyperparameters for this dataset + model\n",
    "                log10Cerr = pd.read_csv(\"base_variants/PAC_hparams.csv\")\\\n",
    "                .query(f\"dataset == '{dataset}'\")[[\"log10Cerr\"]].values[0,0]\n",
    "                log10Cerr = int(log10Cerr)\n",
    "\n",
    "                # load in the file + get the values that we should be plotting\n",
    "                logs_inst = pd.read_csv(f\"../hparam_tuning/results/{model}/{dataset}/model={model}_log10Cerr={log10Cerr}_seed={seed}_metrics.csv\")\n",
    "\n",
    "            elif model == \"FSOL\":\n",
    "\n",
    "                # immediately load in the best hyperparameters for this dataset + model\n",
    "                log2eta, log10lmbda = pd.read_csv(\"base_variants/FSOL_hparams.csv\")\\\n",
    "                .query(f\"dataset == '{dataset}'\")[[\"log2eta\", \"log10lmbda\"]].values[0]\n",
    "                log2eta, log10lmbda = log2eta, log10lmbda\n",
    "\n",
    "                # load in the file + get the values that we should be plotting\n",
    "                logs_inst = pd.read_csv(f\"../hparam_tuning/results/{model}/{dataset}/model={model}_log2eta={log2eta}_log10lmbda={log10lmbda}_seed={seed}_metrics.csv\")\n",
    "                \n",
    "            # create our row\n",
    "            row = [dataset, model, seed, \n",
    "                   logs_inst[\"inst_test-set-acc\"].values[-1], \n",
    "                   logs_inst[\"inst_test-set-hinge\"].values[-1], \n",
    "                   logs_inst[\"inst_sparsity\"].values[-1], \n",
    "                   (logs_inst[\"inst_test-set-acc\"].cummax().values[1:]\\\n",
    "                    - logs_inst[\"inst_test-set-acc\"].values[1:]).mean()]\n",
    "            \n",
    "            # add to our dataframe\n",
    "            baseline_logs.loc[len(baseline_logs.index)] = row\n",
    "            \n",
    "# save our file as a .csv\n",
    "baseline_logs.to_csv(\"logs/baseline_logs.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (Afterburner)\n",
   "language": "python",
   "name": "afterburner"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
